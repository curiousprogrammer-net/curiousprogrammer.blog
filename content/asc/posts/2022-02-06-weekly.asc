{
:date "2022-02-06"
:title "Weekly Bits 03/2022 - Grokking Simplicity, Domain modeling, ..."
:layout :post
:tags  ["weekly-bits" "clojure" "aws" "security" "statistics" "databases"]
}

:toc:
:toclevels: 4



## Clojure



### PF.tv Domain Modeling series

452: Domain Invariants https://purelyfunctional.tv/issues/purelyfunctional-tv-newsletter-452-domain-invariants/
* domain model consists of information, operations, and invariants
* some places to encode invariants: types, (property-based) tests, language features, data structures, runtime checks / assertions, documentation, proofs
453: Model as Toy https://purelyfunctional.tv/issues/purelyfunctional-tv-newsletter-453-model-as-toy/
*  just write it [the model] down - the earlier the better (to spot the problems)
* you have a model anyway, it's just often ad hoc and partically written 

### Clojure cheatsheet - collections functions: `every?`, `not-every?`, `not-any?`

* every? (hopefully obvious)
+
[source,clojure]
----
(every? pos? [1 0 100])
;;=> false
user> (every? pos? [1 10 100])
;;=> true
----
* not-every? (read *_"at least one that is not"_*)
** it's a complement to `every?`

+
[source,clojure]
----
(not-every? pos? [1 0 100])
;;=> true
(not-every? pos? [1 10 100])
;;=> false
----
* not-any? (read *_"none"_*)
** Note: any? is a completely different predicate (it's not really a collection functionreturns true for _any_ argument, including nil)

+
[source,clojure]
----
(not-any? pos? [-1 0 -100])
;;=> true
user> (not-any? pos? [-1 0 100])
;;=> false
----

### Clojure functions reloaded

 https://clojurians.slack.com/archives/C03S1KBA2/p1643466684411559?thread_ts=1643396807.132739&cid=C03S1KBA2[Slack discussion about clojure functions reloadability]:

* Joshua Suskalo: @jumar when you are making like a data literal or something and you put a function name in it and the data structure is evaluated (and since it's a data structure it evaluates to itself), that means that the function name is looked up as a var, and because it's a var it gets dereferenced, and what's in the var is a function object. 
    * So now you have a data structure with a function object in it. 
    * If you now go and change the function and re-evaluate it, a brand new function object is created and put into the var.
    *  The data structure isn't updated because it doesn't know about the var, it just has a function object that points to what the programmer now thinks of as outdated code.
* This is the root cause of all the var indirection reloadability woes. 
    * Any time you pass a function as an argument to the construction of a persistent object, or to the start of a long-lived process, you'll run into this "problem".
* In these cases the way to fix the problem is to introduce a level of indirection, so that whenever the code wants to call the function, it has to first look up the var. 
    * Well as it turns out vars implement the IFn interface, and what they do when called as a function is dereference themselves and then call the result as a function. 
    * So in most of these cases you can get away with just passing a function with a var quote, and now you're not passing a function, you're passing a var.
* The reason this sometimes gets confusing is because you can have one snippet of code where different lines are executed at different times, either because it's in a macro, or because some code is in a lambda and some is not. 
    * Vars are looked up when the code is run, not when it's compiled (besides to just validate that you're not referencing an unbound var), so that means that you can have code in a lambda that "reloads just fine" while other code does not, and that's all because of when the evaluation happens.
* Clojure internals - vars, evaluation, compiler, classloading
* see also my clojure-experiments.reload-vars



### Downloading zip file from an URL via clj-http in Clojure - e.g. Amplitude Export API

[source,clojure]
----
(defn download-events [output-file]
  (let [response (http/get "https://amplitude.com/api/2/export?start=20220131T01&end=20220131T23"
                       {:basic-auth ["api key" "secret key"]
                        :as :stream})]
    (io/copy (:body response) (io/file output-file))))
----


## Coda Hale, Dan McKinley and Finite State Machines (and more)

Through the
[https://blog.skyliner.io/fourteen-months-with-clojure-beb8b3e4bf00[Fourteen Months with Clojure]
blog post (which wasn't that interesting for me)
I discovered a few interesting posts by Coda Hale and Dan McKinley (see also http://datadriven.club/[Data Driven Products]).

### https://blog.skyliner.io/on-the-difficulty-of-conjuring-up-a-dryad-16e33e71b055[On The Difficulty Of Conjuring Up A Dryad]

Talks about 3 interesting topics:

1. *A Finite-State Machine*
** One of their earliest major design decision was to model the Skyliner deploy process as a Finite-State Machine (FSM), with transitions from one state to another associated with specific conditions and actions. 
** For example, a deploy in the rollout-wait state will check the newly-launched instances of the deploy. 
*** If the instances are up and running, the deploy is advanced via rollout-ok to the evaluate-wait state. 
*** If the instances have failed to launch, the deploy is advanced via rollout-failed to the rollback state. 
*** If the instances are still launching, the deploy is kept in the rollout-wait state via rollout-in-progress.

2. *A Reliable Coordinator* (Amazon SQS)
SQS has a very robust model for dealing with failures: when a consumer polls the server for a new message, it specifies a visibility timeout
    * Similarly, when sending a message to a queue, one can specify a delay
    * We use the delay and the visibility timeouts to create “ticks” for deploys.
        * When a deploy is started, we send an SQS message with the deploy ID, environment, etc. using a delay of e.g. 10 seconds. 
        * After 10 seconds, it becomes visible to a Skyliner background thread, which receives it using a visibility timeout of e.g. 10 seconds. 
            * The thread looks up the deploy’s current state and takes any appropriate action to advance it. 
            * If the deploy has finished, the thread deletes the message from the queue. 
            * Otherwise, the message is left in the queue to reappear after another 10 seconds has passed.

3. *Blue-Green Deploys*
** Instead of modifying servers in-place and hoping nothing goes wrong, we leverage EC2’s elasticity and launch an entirely new set of instances
** roll back by terminating the new instances

### https://blog.skyliner.io/you-cant-have-a-rollback-button-83e914f420d9[You Can’t Have a Rollback Button]
* The fundamental problem with rolling back to an old version is that web applications are not self-contained, and therefore they do not have versions. 
** They have a current state - the application code and everything that it interacts with. Databases, caches, browsers, and concurrently-running copies of itself.
* One example of the problem - corrupting a cache (simple rollback might not fix the cache)
* Takeaway: favor feature flags (disable them if there's a problem) and roll forward (reverting a smaller diff instead of trying to revert all the other changes that were also released with/since the problematic change)



## Java / JVM



## AWS & Cloud


### Audrey Lawrence on Time Series Databases & Amazon Timestream

* really good podcast about Amazon Timestream and how time series databases work in general
* CodeScene onboarding - Enys Mones
    * a time series database could be a good alternative / supplement to Amplitude - we could send events data there too

## Books

### https://github.com/jumarko/grokking-simplicity[Grokking Simplicity] - Introduction

* reading the intro, skimming the book and the first chapter
* two main ideas/skills: 
    * distinguishing actions, calculations, data
    * using first-class abstractions such as higher-order functions (powerful technique for reuse to pass functions to other functions)


* coupon email process - process diagram very useful !
* created the repo and added some examples: https://github.com/jumarko/grokking-simplicity/commit/2cb5e0d695cc5f2bc8b8f1035e3433125fd15843#diff-b637808dc30c25abf4c4b912947c3c84708eae9ae010cf360574c736bb5a7707
* data should ideally mirror the structure of the domain
* p.42: Data as a records of the DB at given point in time
* separate data generation from its usage
* split large calculations into smaller - e.g. plan list of emails into: 
    * select good coupons
    * select best coupons
    * decide coupon rank
    * generate email
* action "ties it all together"
    * when you need to optimize the process start in the high-level action - e.g. processing data in pages 
        * calculations often don't need to change at all!



### https://github.com/jumarko/api-security-in-action[Api Security in Action] - HMAC & Timing attacks

API Security in Action (book) -> p.172-176
* a simple hash is stored in the database and HMAC tag is appended to the token
* the token-hash.tag is given to the client and tag is computed for every request
/* token generation */
tag = hmac(tokenId)
// return this token to the user; store tokenId in the DB
userToken = tokenId + "." + Base64.encode(tag)

/* request veritification */
providedTag = Base64.decode(token.substringAfter("."))
computedTag = hmac(realTokenId)
// using MessageDigest prevents timing attacks
if (!MessageDigest.isEqual(providedTag, computedTag) {
   // invalid tag -> return/throw without querying the DB
}
...
* invalid requests which produce an invalid tag are rejected immediately without DB query => avoiding timing attacks
    * make sure to use MessageDigest.isEqual to compare the expected and the computed HMAC tag
* token (SQL) injection is prevented because an attacker cannot produce a valid hash even if they have access to the database (they don't have the secret key)


### https://www.amazon.com/Practical-Monitoring-Effective-Strategies-World/dp/1491957352[Practical Monitoring] - Basic statistics

Chapter 4 in the book is short but _practical_ (as the whole book even though it focuses on principles and not particular tools).

* It's a quick tour of the most basic statistics like mean, median, and percentiles.
* It says that *standard deviation is rarely useful* because we mostly deal with not-normal distributions (_skew_)
* It also talks about an important statistical concept, *seasonability* - repeating patterns like a weekly cpu usage.
* Advise to look for *_skew_*, *_outliers*_, and *_bounds*_ when thinking about your data


### https://fiftyquickideas.com/fifty-quick-ideas-to-improve-your-user-stories/[50 Quick Ideas to improve your user stories]

#### Impact mapping

Powerful technique, hierarchical backlogs

* read the Book Sample: https://www.impactmapping.org/assets/impact_mapping_20121001_sample.pdf
* Impact mapping has several unique advantages over similar methods:
    * 1. [based on interaction design] facilitates collaboration and interaction between both technical experts and business users
    * 2. It visualises assumptions - Alternative models mostly do not communicate assumptions clearly.
        * supports effective meetings and big-picture thinking
    * 3. It's fast - a couple of days might save you months
        * => fits well with iterative delivery
* Actors - focus  who will benefit from it and who will be worse off when it is delivered
    * do not focus on software features / capabilities
    * define actors in this order: specific individual, user persona, role or job title, group or department
* goals - very few people working on delivery know the actual expected business objectives
    * sometimes drafted in a vision document, but more frequently exist only at the back of senior stakeholders’ minds.
    * By having the answer to ‘WHY?’ in the centre, impact maps ensure that everyone knows why they are doing something.
* impacts - understand what jobs customers want to get done instead of their ideas about a product or service.
    * consider negative impacts too
        * CodeScene cloud example: increasing number of customers and successful trials will likely increase load on the support team
* deliverables - Start only with high-level deliverables
    * You can break down high-level features into lower-level scope items, such as user stories, spine stories, basic or extension use cases later.



## Writing



## MISC

### PurePerformance podcast

https://www.dynatrace.com/news/pureperformance/

### TODO: move to next week's summary

http://www.pixelbeat.org/programming/stdio_buffering/[Linux pipes and standard streams buffering problems]

    * Default Buffering modes:
        * stdin is buffered (line buffering doesn't affect stdin)
        * stdout is buffered (line buffered if connected to a terminal)
        * stderr is unbuffered
    * Default Buffer sizes:
        * Buffer size only directly affects buffered mode
        * The default size like the kernel is based on the page size (4096 bytes on my system)
        * if stdin/stdout are connected to a terminal then default size = 1024; else size = 4096
+
image::/img/2022-02-06-weekly/stdio-buffering.png[Linux pipes & stdio output buffering problems, 622, 394]

        *  and hence will automatically buffer up data into 4096 byte chunks before sending to uniq.
        * Note tail's stdout buffer would also have this problem, but tail -f calls fflush on the stdout stream when new data is received to alleviate this (as do tcpdump -l, grep --line-buffered and sed --unbuffered for example).
        * Note also that uniq's stdout buffer is connected to a terminal and so will be automatically flushed when a new line is written to it which is fine for our needs.




### Microsoft Excel highlighting duplicate values & hiding columns

highlighting duplicate values:  https://answers.microsoft.com/en-us/msoffice/forum/all/2011-excel-for-mac-how-to-highlight-duplicate/7afdb7e3-a9f7-4dfc-a410-a49907e4448b?auth=1

* Go to Format - Conditional formatting

hide columns: https://www.knowledgewave.com/blog/hiding-columns-and-rows-in-excel-the-easy-way


## Links

A quick recap of some of the links mentioned in this post:

* 




